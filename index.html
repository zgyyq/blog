<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">


<link rel="stylesheet" href="/blog/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zgyyq.github.io","root":"/blog/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="最光阴写字的地方">
<meta property="og:url" content="https://zgyyq.github.io/blog/index.html">
<meta property="og:site_name" content="最光阴写字的地方">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="最光阴">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://zgyyq.github.io/blog/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>最光阴写字的地方</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">最光阴写字的地方</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/blog/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/blog/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/blog/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/blog/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/blog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zgyyq.github.io/blog/2023/04/30/kafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6/%E3%80%8CKafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6%E3%80%8D%E4%B9%8BBufferPool/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="最光阴">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="最光阴写字的地方">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/2023/04/30/kafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6/%E3%80%8CKafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6%E3%80%8D%E4%B9%8BBufferPool/" class="post-title-link" itemprop="url">post</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-04-30 19:11:43" itemprop="dateCreated datePublished" datetime="2023-04-30T19:11:43+08:00">2023-04-30</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zgyyq.github.io/blog/2023/04/29/kafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6/%E3%80%8CKafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6%E3%80%8D%E4%B9%8B%E7%BD%91%E7%BB%9C%E5%8F%91%E9%80%81/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="最光阴">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="最光阴写字的地方">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/2023/04/29/kafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6/%E3%80%8CKafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6%E3%80%8D%E4%B9%8B%E7%BD%91%E7%BB%9C%E5%8F%91%E9%80%81/" class="post-title-link" itemprop="url">「Kafka源码美学」之网络发送</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-04-29 23:45:25" itemprop="dateCreated datePublished" datetime="2023-04-29T23:45:25+08:00">2023-04-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-04-30 18:58:27" itemprop="dateModified" datetime="2023-04-30T18:58:27+08:00">2023-04-30</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/Kafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6/" itemprop="url" rel="index"><span itemprop="name">Kafka源码美学</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>通过「Kafka源码美学」之Sender线程文章中，我们知道Sender最终把消息发送出去，依靠的是Kafka核心组件 - NetWorkClient。它负责Kafka所有的网络IO，包括连接的建立，读数据、写数据等等。</p>
<p>而NetworkClient是基于Java Nio封装的，所以在阅读本文前需要了解Java Nio的基础知识。</p>
<p>让我们先来看看网络发送的流程图吧：</p>
<h2 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h2><p><img src="/blog/img/kafka%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97/kafka%E7%BD%91%E7%BB%9C%E5%B1%82%E8%AE%BE%E8%AE%A1.png" alt="img"></p>
<p>上面流程图是Kafka producer网络层的主体流程，结合之前的文章，相信你能有一个大体的印象。</p>
<p>Kafka的网络层是基于Java NIO封装的。<br>Kafka中针对NIO的Selector的封装类也叫Selector，对Channel的封装类叫做KafkaChannel。注意这里需要区分两个Selector</p>
<ol>
<li>Kafka的Selector：org.apache.kafka.common.network.Selector</li>
<li>Java的Selector：java.nio.channels.Selector</li>
</ol>
<p>首先看下NetworkClient的核心字段解释。</p>
<h2 id="核心字段"><a href="#核心字段" class="headerlink" title="核心字段"></a>核心字段</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaChannel</span> &#123;</span><br><span class="line">  <span class="comment">//继承java.nio.channels.Channel，可读可写,对socketChannel的封装</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> TransportLayer transportLayer;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//通过它来创建Buffer和回收Buffer</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> MemoryPool memoryPool;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//收到的数据</span></span><br><span class="line">  <span class="keyword">private</span> NetworkReceive receive;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//发送的数据</span></span><br><span class="line">  <span class="keyword">private</span> Send send;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Selector</span> <span class="keyword">implements</span> <span class="title class_">Selectable</span>, AutoCloseable &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//java nio中的Selector</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> java.nio.channels.Selector nioSelector;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//kafka服务器节点和Channel之间对应关系</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String, KafkaChannel&gt; channels;</span><br><span class="line">  <span class="comment">//发送完成的请求</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> List&lt;Send&gt; completedSends;</span><br><span class="line">  <span class="comment">//完整的消息响应</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> List&lt;NetworkReceive&gt; completedReceives;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//暂存的消息响应</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;KafkaChannel, Deque&lt;NetworkReceive&gt;&gt; stagedReceives;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//立即连接上的SelectionKey</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> Set&lt;SelectionKey&gt; immediatelyConnectedKeys;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//用于分配ByteBuffer</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> MemoryPool memoryPool;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>接下里我们来看看具体的源码实现。</p>
<h2 id="消息预发送"><a href="#消息预发送" class="headerlink" title="消息预发送"></a>消息预发送</h2><p>由「Kafka源码美学」之Sender线程文章中知道，sender线程调用KafkaClient.send()，将待发送的数据暂存到队列中，等待触发网络IO完成发送。核心的实现在doSend()方法中</p>
<h3 id="KafkaClient-doSend"><a href="#KafkaClient-doSend" class="headerlink" title="KafkaClient.doSend()"></a>KafkaClient.doSend()</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">doSend</span><span class="params">(ClientRequest clientRequest, <span class="type">boolean</span> isInternalRequest, <span class="type">long</span> now, AbstractRequest request)</span> &#123;</span><br><span class="line">     <span class="comment">// 获取请求目标地址</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">destination</span> <span class="operator">=</span> clientRequest.destination();</span><br><span class="line">    <span class="comment">// 构造请求头</span></span><br><span class="line">    <span class="type">RequestHeader</span> <span class="variable">header</span> <span class="operator">=</span> clientRequest.makeHeader(request.version());</span><br><span class="line">     <span class="comment">// 将请求对象转换成网络发送对象</span></span><br><span class="line">    <span class="type">Send</span> <span class="variable">send</span> <span class="operator">=</span> request.toSend(header);</span><br><span class="line">    <span class="comment">// 构造待发送请求对象</span></span><br><span class="line">    <span class="type">InFlightRequest</span> <span class="variable">inFlightRequest</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">InFlightRequest</span>(</span><br><span class="line">            clientRequest,</span><br><span class="line">            header,</span><br><span class="line">            isInternalRequest,</span><br><span class="line">            request,</span><br><span class="line">            send,</span><br><span class="line">            now);</span><br><span class="line">    <span class="comment">// 添加到发送队列</span></span><br><span class="line">    <span class="built_in">this</span>.inFlightRequests.add(inFlightRequest);</span><br><span class="line">    <span class="comment">// 发送请求</span></span><br><span class="line">    selector.send(<span class="keyword">new</span> <span class="title class_">NetworkSend</span>(clientRequest.destination(), send));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法主要的步骤包括：构造请求头部，将请求对象转换成网络发送对象，构造待发送请求对象，并将其添加到发送队列中，最后发送请求给Broker端。其中，InFlightRequest对象表示待发送的请求对象，NetworkSend对象表示网络发送对象。</p>
<h3 id="Selector-send"><a href="#Selector-send" class="headerlink" title="Selector.send()"></a>Selector.send()</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 发送网络发送对象给Broker端</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> send 网络发送对象</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">send</span><span class="params">(NetworkSend send)</span> &#123;</span><br><span class="line">    <span class="comment">// 获取目标地址的连接ID</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">connectionId</span> <span class="operator">=</span> send.destinationId();</span><br><span class="line">    <span class="comment">// 获取或创建连接通道</span></span><br><span class="line">    <span class="type">KafkaChannel</span> <span class="variable">channel</span> <span class="operator">=</span> openOrClosingChannelOrFail(connectionId);</span><br><span class="line">    <span class="keyword">if</span> (closingChannels.containsKey(connectionId)) &#123; </span><br><span class="line">        <span class="comment">// 如果连接通道正在关闭，则将其添加到failedSends中等待处理</span></span><br><span class="line">        <span class="built_in">this</span>.failedSends.add(connectionId);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 否则将网络发送对象设置到连接通道上</span></span><br><span class="line">            channel.setSend(send);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从源码中可以看到调用了 KafkaChannel 类的 setSend() 方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSend</span><span class="params">(Send send)</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">this</span>.send != <span class="literal">null</span>)</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalStateException</span>(<span class="string">&quot;Attempt to begin a send operation with prior send operation still in progress, connection id is &quot;</span> + id);</span><br><span class="line">  <span class="comment">// 设置要发送消息的字段</span></span><br><span class="line">  <span class="built_in">this</span>.send = send;</span><br><span class="line">  <span class="comment">// 调用传输层增加写事件</span></span><br><span class="line">  <span class="built_in">this</span>.transportLayer.addInterestOps(SelectionKey.OP_WRITE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addInterestOps</span><span class="params">(<span class="type">int</span> ops)</span> &#123;</span><br><span class="line">    <span class="comment">//通过 key.interestOps() | ops 来添加事件</span></span><br><span class="line">    key.interestOps(key.interestOps() | ops);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个方法的主要作用是在发送网络请求之前，将需要发送的ByteBuffer数据保存到KafkaChannel对象的send字段中，然后调用传输层方法注册该通道对「OP_WRITE」事件的关注，同时保留「OP_READ」事件，因此此时该通道是可以同时进行读写操作的。当真正执行发送时，将从send字段中读取数据发送。因此，该方法实现了预先将待发送数据写入缓存，等待网络传输的功能。</p>
<h2 id="消息真正发送"><a href="#消息真正发送" class="headerlink" title="消息真正发送"></a>消息真正发送</h2><p>在分析sender线程的文章中提到，消息真正发送的链路是：<br>Sender.run() -&gt; NetworkClient.poll() -&gt; KSelector.poll() –&gt; nioSelector.select()</p>
<p>让我们来看下KSelector.poll()：</p>
<h3 id="Selector-poll"><a href="#Selector-poll" class="headerlink" title="Selector.poll()"></a>Selector.poll()</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">poll</span><span class="params">(<span class="type">long</span> timeout)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="comment">// 调用nioSelector.select线程阻塞等待I/O事件并设置阻塞时间，等待I/O事件就绪发生，然后返回已经监控到了多少准备就绪的事件</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">numReadyKeys</span> <span class="operator">=</span> select(timeout);</span><br><span class="line">    <span class="type">boolean</span> <span class="variable">dataInBuffers</span> <span class="operator">=</span> !keysWithBufferedRead.isEmpty();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 监听到事件发生</span></span><br><span class="line">    <span class="keyword">if</span> (numReadyKeys &gt; <span class="number">0</span> || !immediatelyConnectedKeys.isEmpty() || dataInBuffers) &#123;</span><br><span class="line">        <span class="keyword">if</span> (dataInBuffers) &#123;</span><br><span class="line">            <span class="comment">// 处理缓冲数据轮训事件</span></span><br><span class="line">            pollSelectionKeys(toPoll, <span class="literal">false</span>, endSelect);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 处理处理就绪事件</span></span><br><span class="line">        pollSelectionKeys(readyKeys, <span class="literal">false</span>, endSelect);</span><br><span class="line">        <span class="comment">// 处理立即连接集合</span></span><br><span class="line">        pollSelectionKeys(immediatelyConnectedKeys, <span class="literal">true</span>, endSelect);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在 poll() 方法中，pollSelectionKeys方法会调用三次：</p>
<ol>
<li>处理从具有缓冲数据的通道的轮询事件</li>
<li>处理已经就绪的事件，进行相应的 IO 操作。</li>
<li>处理新建立的那些连接，添加缓存及传输层的握手与认证。</li>
</ol>
<p>Selector.select() 方法底层还是调用的 Java NIO 的原生接口，这里的 nioSelector 其实就是 java.nio.channels.Selector 的实例对象，这个方法最坏情况下，会阻塞 ms 的时间，如果在一次轮询，只要有一个 Channel 的事件就绪，它就会立马返回。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="type">int</span> <span class="title function_">select</span><span class="params">(<span class="type">long</span> timeoutMs)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="keyword">if</span> (timeoutMs &lt; <span class="number">0L</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;timeout should be &gt;= 0&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (timeoutMs == <span class="number">0L</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.nioSelector.selectNow();</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.nioSelector.select(timeoutMs);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>再来看pollSelectionKeys()方法</p>
<h3 id="Selector-pollSelectionKeys"><a href="#Selector-pollSelectionKeys" class="headerlink" title="Selector.pollSelectionKeys()"></a>Selector.pollSelectionKeys()</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> <span class="title function_">pollSelectionKeys</span><span class="params">(Set&lt;SelectionKey&gt; selectionKeys,</span></span><br><span class="line"><span class="params">                       <span class="type">boolean</span> isImmediatelyConnected,</span></span><br><span class="line"><span class="params">                       <span class="type">long</span> currentTimeNanos)</span> &#123;</span><br><span class="line">  <span class="comment">// 循环调用当前监听到的事件</span></span><br><span class="line">  <span class="keyword">for</span> (SelectionKey key : determineHandlingOrder(selectionKeys)) &#123;</span><br><span class="line">    <span class="comment">// 之前创建连接，把kafkachanel注册到key上，这里就是获取对应的 channel</span></span><br><span class="line">    <span class="type">KafkaChannel</span> <span class="variable">channel</span> <span class="operator">=</span> channel(key);</span><br><span class="line">    <span class="comment">// 判断channel是否就绪，有可读数据，未完成接收，则尝试处理读事件</span></span><br><span class="line">    <span class="keyword">if</span> (channel.ready() &amp;&amp; (key.isReadable() || channel.hasBytesBuffered()) &amp;&amp; !hasCompletedReceive(channel) &amp;&amp; !explicitlyMutedChannels.contains(channel)) &#123;</span><br><span class="line">        <span class="comment">// 尝试处理读事件</span></span><br><span class="line">        attemptRead(channel);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 尝试处理写事件</span></span><br><span class="line">        attemptWrite(key, channel, nowNanos);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="attemptRead"><a href="#attemptRead" class="headerlink" title="attemptRead"></a>attemptRead</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">attemptWrite</span><span class="params">(SelectionKey key, KafkaChannel channel, <span class="type">long</span> nowNanos)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">   <span class="comment">// 满足条件进行写操作</span></span><br><span class="line">   <span class="keyword">if</span> (channel.hasSend()</span><br><span class="line">                &amp;&amp; channel.ready()</span><br><span class="line">                &amp;&amp; key.isWritable()</span><br><span class="line">                &amp;&amp; !channel.maybeBeginClientReauthentication(() -&gt; nowNanos)) &#123;</span><br><span class="line">        write(channel);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="attemptRead-1"><a href="#attemptRead-1" class="headerlink" title="attemptRead"></a>attemptRead</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> <span class="title function_">write</span><span class="params">(KafkaChannel channel)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">nodeId</span> <span class="operator">=</span> channel.id();</span><br><span class="line">    <span class="comment">// 将保存在 send 上的数据真正发送出去，但是一次不一定能发送完，会返回已经发出的字节数</span></span><br><span class="line">    <span class="type">long</span> <span class="variable">bytesSent</span> <span class="operator">=</span> channel.write();</span><br><span class="line">    <span class="comment">// 判断是否发送完成，未完成返回null，等待下次poll继续发送</span></span><br><span class="line">    <span class="type">NetworkSend</span> <span class="variable">send</span> <span class="operator">=</span> channel.maybeCompleteSend();</span><br><span class="line">    <span class="keyword">if</span> (bytesSent &gt; <span class="number">0</span> || send != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 发送完成</span></span><br><span class="line">        <span class="keyword">if</span> (send != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 将 send 添加到 completedSends</span></span><br><span class="line">            <span class="built_in">this</span>.completedSends.add(send);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>该方法主要用来真正执行网络写操作。</p>
<h3 id="KafkaChannel-write"><a href="#KafkaChannel-write" class="headerlink" title="KafkaChannel.write()"></a>KafkaChannel.write()</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">long</span> <span class="title function_">write</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="comment">// 判断 send 是否为空，如果为空表示已经发送完毕了</span></span><br><span class="line">    <span class="keyword">if</span> (send == <span class="literal">null</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    midWrite = <span class="literal">true</span>;</span><br><span class="line">    <span class="comment">// 调用ByteBufferSend.writeTo把数据真正发送出去</span></span><br><span class="line">    <span class="keyword">return</span> send.writeTo(transportLayer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="ByteBufferSend-writeTo"><a href="#ByteBufferSend-writeTo" class="headerlink" title="ByteBufferSend.writeTo"></a>ByteBufferSend.writeTo</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 将数据写入传输通道</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">long</span> <span class="title function_">writeTo</span><span class="params">(TransferableChannel channel)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="comment">// 通过传输通道写入数据到缓冲区中</span></span><br><span class="line">    <span class="type">long</span> <span class="variable">written</span> <span class="operator">=</span> channel.write(buffers);</span><br><span class="line">    <span class="keyword">if</span> (written &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">EOFException</span>(<span class="string">&quot;Wrote negative bytes to channel. This shouldn&#x27;t happen.&quot;</span>);</span><br><span class="line">    <span class="comment">// 更新缓冲区中剩余数据的字节数</span></span><br><span class="line">    remaining -= written;</span><br><span class="line">    <span class="comment">// 检查传输通道是否有未写入的数据</span></span><br><span class="line">    pending = channel.hasPendingWrites();</span><br><span class="line">    <span class="comment">// 返回已写入的字节数</span></span><br><span class="line">    <span class="keyword">return</span> written;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法主要用来把 buffers 数组写入到 SocketChannel 里，因为在网络编程中，写一次不一定可以完全把数据都写成功，所以调用java nio 底层 channel.write(buffers) 方法会返回「已经写入成功多少字节」的返回值，这样调用一次后就知道已经写入多少字节了。</p>
<h3 id="maybeCompleteSend"><a href="#maybeCompleteSend" class="headerlink" title="maybeCompleteSend"></a>maybeCompleteSend</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Send <span class="title function_">maybeCompleteSend</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// send 不为空且已经发送完毕</span></span><br><span class="line">    <span class="keyword">if</span> (send != <span class="literal">null</span> &amp;&amp; send.completed()) &#123;</span><br><span class="line">        midWrite = <span class="literal">false</span>;</span><br><span class="line">        <span class="comment">// 当写数据完毕后，取消传输层对 OP_WRITE 事件的监听，完成一次写操作</span></span><br><span class="line">        transportLayer.removeInterestOps(SelectionKey.OP_WRITE);</span><br><span class="line">        <span class="comment">// 将 send 赋值给结果集 result</span></span><br><span class="line">        <span class="type">Send</span> <span class="variable">result</span> <span class="operator">=</span> send;</span><br><span class="line">        <span class="comment">// 此时读完后将 send 清空，以便下次写</span></span><br><span class="line">        send = <span class="literal">null</span>;</span><br><span class="line">        <span class="comment">// 最后返回结果集 result，完成一次写操作</span></span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>至此，终于将message 发送到了broker中，让我们来总结一下消息发送的流程</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>产生一条消息，由Producer.send()会以ProducerBatch为单位追加到RecordAccumulator中，sender线程不断读取RecordAccumulator中的数据，包装成ClientRequest，然后调用NetworkClient的接口，发送到broker中</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zgyyq.github.io/blog/2023/04/28/kafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6/%E3%80%8CKafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6%E3%80%8D%E4%B9%8BSender%E7%BA%BF%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="最光阴">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="最光阴写字的地方">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/2023/04/28/kafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6/%E3%80%8CKafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6%E3%80%8D%E4%B9%8BSender%E7%BA%BF%E7%A8%8B/" class="post-title-link" itemprop="url">「Kafka源码美学」之Sender线程</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-04-28 17:22:00" itemprop="dateCreated datePublished" datetime="2023-04-28T17:22:00+08:00">2023-04-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-04-30 01:03:05" itemprop="dateModified" datetime="2023-04-30T01:03:05+08:00">2023-04-30</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/Kafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6/" itemprop="url" rel="index"><span itemprop="name">Kafka源码美学</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>回顾之前文章的架构图：</p>
<p><img src="/blog/img/kafka%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97/%E7%94%9F%E4%BA%A7%E8%80%85%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="img"></p>
<p>可知Sender线程扮演中间层的角色，对上承接RecordAccumulator，获取待发送的ProducerBatch，对下调用网络IO，实现真正的网络请求。<br>需要注意的是，<strong>Sender线程是一个单线程</strong>，所以它所有的方法都是线程安全的。</p>
<p>之前文章提到，当初始化KafkaProducer时，会启动一个sender线程。当线程启动后会执行run()方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">this</span>.sender = newSender(logContext, kafkaClient, <span class="built_in">this</span>.metadata);</span><br><span class="line"><span class="built_in">this</span>.ioThread = <span class="keyword">new</span> <span class="title class_">KafkaThread</span>(ioThreadName, <span class="built_in">this</span>.sender, <span class="literal">true</span>);</span><br><span class="line"><span class="built_in">this</span>.ioThread.start();</span><br></pre></td></tr></table></figure>

<h3 id="Run"><a href="#Run" class="headerlink" title="Run"></a>Run</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">       <span class="comment">// main loop, runs until close is called</span></span><br><span class="line">       <span class="keyword">while</span> (running) &#123;</span><br><span class="line">           <span class="keyword">try</span> &#123;</span><br><span class="line">               runOnce();</span><br><span class="line">           &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">               log.error(<span class="string">&quot;Uncaught error in kafka producer I/O thread: &quot;</span>, e);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       <span class="keyword">while</span> (!forceClose &amp;&amp; ((<span class="built_in">this</span>.accumulator.hasUndrained() || <span class="built_in">this</span>.client.inFlightRequestCount() &gt; <span class="number">0</span>) || hasPendingTransactionalRequests())) &#123;</span><br><span class="line">           <span class="keyword">try</span> &#123;</span><br><span class="line">               runOnce();</span><br><span class="line">           &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">               log.error(<span class="string">&quot;Uncaught error in kafka producer I/O thread: &quot;</span>, e);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">while</span> (!forceClose &amp;&amp; transactionManager != <span class="literal">null</span> &amp;&amp; transactionManager.hasOngoingTransaction()) &#123;</span><br><span class="line">           <span class="keyword">try</span> &#123;</span><br><span class="line">               runOnce();</span><br><span class="line">           &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">               log.error(<span class="string">&quot;Uncaught error in kafka producer I/O thread: &quot;</span>, e);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>主要的网络请求都封装到runOnce()方法中，首先让我们来看run()方法中的三次调用吧</p>
<ol>
<li>主循环，直到running状态为false才会退出。running 在Sender类的构造方法中完成了赋值，赋值为true。</li>
<li>当running状态为false才会走到这里，虽然停止接受请求了，但是事务处理器，数据缓存器活或等待确认的还有请求，所以需要等待这些完成。</li>
<li>如果一些提交或者中止没有通过事务管理器管理，那么进行中止。</li>
</ol>
<h3 id="RunOnce"><a href="#RunOnce" class="headerlink" title="RunOnce"></a>RunOnce</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> <span class="title function_">runOnce</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 判断是否为事务操作，对主流程影响不大，故这里不过多解释</span></span><br><span class="line">        <span class="keyword">if</span> (transactionManager != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">// 如果事务管理器有错误，那么停止运行，不再继续发送</span></span><br><span class="line">                <span class="keyword">if</span> (transactionManager.hasFatalError()) &#123;</span><br><span class="line">                    client.poll(retryBackoffMs, time.milliseconds());</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// Check whether we need a new producerId. If so, we will enqueue an InitProducerId</span></span><br><span class="line">                <span class="comment">// request which will be sent below</span></span><br><span class="line">                transactionManager.bumpIdempotentEpochAndResetIdIfNeeded();</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (maybeSendAndPollTransactionalRequest()) &#123;</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (AuthenticationException e) &#123;</span><br><span class="line">                <span class="comment">// This is already logged as error, but propagated here to perform any clean ups.</span></span><br><span class="line">                log.trace(<span class="string">&quot;Authentication exception while processing transactional request&quot;</span>, e);</span><br><span class="line">                transactionManager.authenticationFailed(e);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">long</span> <span class="variable">currentTimeMs</span> <span class="operator">=</span> time.milliseconds();</span><br><span class="line">        <span class="comment">// sender线程具体执行的地方</span></span><br><span class="line">        <span class="type">long</span> <span class="variable">pollTimeout</span> <span class="operator">=</span> sendProducerData(currentTimeMs);</span><br><span class="line">        <span class="comment">// 实际的socket io操作</span></span><br><span class="line">        client.poll(pollTimeout, currentTimeMs);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>实际发送数据的方法都封装在sendProducerData中，网络IO操作封装在poll()方法中，接下来让我们一一解析。</p>
<h3 id="SendProducerData"><a href="#SendProducerData" class="headerlink" title="SendProducerData"></a>SendProducerData</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="type">long</span> <span class="title function_">sendProducerData</span><span class="params">(<span class="type">long</span> now)</span> &#123;</span><br><span class="line">        <span class="comment">// 1. 拉取集群元数据信息</span></span><br><span class="line">        <span class="type">Cluster</span> <span class="variable">cluster</span> <span class="operator">=</span> metadata.fetch();</span><br><span class="line">        <span class="comment">// 2. 获取可以发送recordBatch的分区列表</span></span><br><span class="line">        RecordAccumulator.<span class="type">ReadyCheckResult</span> <span class="variable">result</span> <span class="operator">=</span> <span class="built_in">this</span>.accumulator.ready(cluster, now);</span><br><span class="line">        <span class="comment">// 3. 获取所有可以发送的ProducerBatch（key是node.id,value是发送到该node的request列表）</span></span><br><span class="line">        Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; batches = <span class="built_in">this</span>.accumulator.drain(cluster, result.readyNodes, <span class="built_in">this</span>.maxRequestSize, now);</span><br><span class="line">        <span class="comment">// 增加到 inFlightBatches 发送中队列</span></span><br><span class="line">        addToInflightBatches(batches);</span><br><span class="line">        <span class="comment">// 保证一个partition只有一个recordBatch在发送，保证了有序性。max.in.flight.requests.per.connection设置为1时会保证</span></span><br><span class="line">        <span class="keyword">if</span> (guaranteeMessageOrder) &#123;</span><br><span class="line">            <span class="comment">// Mute all the partitions drained</span></span><br><span class="line">            <span class="keyword">for</span> (List&lt;ProducerBatch&gt; batchList : batches.values()) &#123;</span><br><span class="line">                <span class="keyword">for</span> (ProducerBatch batch : batchList)</span><br><span class="line">                    <span class="built_in">this</span>.accumulator.mutePartition(batch.topicPartition);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 过期数据处理</span></span><br><span class="line">        accumulator.resetNextBatchExpiryTime();</span><br><span class="line">        <span class="comment">// 获取发送超时的列表</span></span><br><span class="line">        List&lt;ProducerBatch&gt; expiredInflightBatches = getExpiredInflightBatches(now);</span><br><span class="line">        <span class="comment">// 获取在 accumulator 时间太久了，已经要过期了的batches</span></span><br><span class="line">        List&lt;ProducerBatch&gt; expiredBatches = <span class="built_in">this</span>.accumulator.expiredBatches(now);</span><br><span class="line">        <span class="comment">// 将发送时间超时的列表加入到过期列表中</span></span><br><span class="line">        expiredBatches.addAll(expiredInflightBatches);</span><br><span class="line">        <span class="comment">// 5. 发送 Producer 请求，这个方法会调用 NetworkClient.send() 来发送 clientRequest。</span></span><br><span class="line">        sendProduceRequests(batches, now);</span><br><span class="line">        <span class="keyword">return</span> pollTimeout;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码可以看出 sendProducerData 主要分为5个步骤</p>
<ol>
<li>从缓存中获取集群元数据信息，后续所有操作都依赖元数据信息。</li>
<li>根据元数据信息的集群信息，获取accumulator中所有已经ready的batches。</li>
<li>根据broker进行数据分组，因为同一个broker可能有很多个partition，为了减少网络请求的开销，将同一个Node节点的数据聚合在一起。</li>
<li>超时&amp;过期数据处理</li>
<li>调用NetworkClient完成网络操作，NetworkClient底层依赖于Select来完成。注意这个方法只是为网络发送作准备，将数据放到一个等待队列中，而真正的网络IO操作发生在Client.poll()中</li>
</ol>
<p>下面分析client.poll()方法</p>
<h3 id="client-poll"><a href="#client-poll" class="headerlink" title="client.poll()"></a>client.poll()</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;ClientResponse&gt; <span class="title function_">poll</span><span class="params">(<span class="type">long</span> timeout, <span class="type">long</span> now)</span> &#123;</span><br><span class="line">        ensureActive();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!abortedSends.isEmpty()) &#123;</span><br><span class="line">            <span class="comment">// If there are aborted sends because of unsupported version exceptions or disconnects,</span></span><br><span class="line">            <span class="comment">// handle them immediately without waiting for Selector#poll.</span></span><br><span class="line">            List&lt;ClientResponse&gt; responses = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">            handleAbortedSends(responses);</span><br><span class="line">            completeResponses(responses);</span><br><span class="line">            <span class="keyword">return</span> responses;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 判断是否需要更新元数据</span></span><br><span class="line">        <span class="type">long</span> <span class="variable">metadataTimeout</span> <span class="operator">=</span> metadataUpdater.maybeUpdate(now);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 调用Selector.poll()进行socket IO操作</span></span><br><span class="line">            <span class="built_in">this</span>.selector.poll(Utils.min(timeout, metadataTimeout, defaultRequestTimeoutMs));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            log.error(<span class="string">&quot;Unexpected error during I/O&quot;</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// process completed actions</span></span><br><span class="line">        <span class="type">long</span> <span class="variable">updatedNow</span> <span class="operator">=</span> <span class="built_in">this</span>.time.milliseconds();</span><br><span class="line">        List&lt;ClientResponse&gt; responses = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        <span class="comment">// 处理已经完成的请求发送</span></span><br><span class="line">        handleCompletedSends(responses, updatedNow);</span><br><span class="line">        <span class="comment">// 处理从server端收到的response</span></span><br><span class="line">        handleCompletedReceives(responses, updatedNow);</span><br><span class="line">        <span class="comment">// 处理连接失败的请求</span></span><br><span class="line">        handleDisconnections(responses, updatedNow);</span><br><span class="line">        <span class="comment">// 处理新建立的连接(还不能发送请求)</span></span><br><span class="line">        handleConnections();</span><br><span class="line">        <span class="comment">// 对新建立的连接，发送apiVersionRequests请求</span></span><br><span class="line">        handleInitiateApiVersionRequests(updatedNow);</span><br><span class="line">        <span class="comment">// 处理timeout的连接，关闭连接</span></span><br><span class="line">        handleTimedOutConnections(responses, updatedNow);</span><br><span class="line">        handleTimedOutRequests(responses, updatedNow);</span><br><span class="line">        completeResponses(responses);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> responses;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Send线程中主要做了如下几件事：</p>
<ul>
<li>获取accumulator中已经ready的producerBatch，并转化为以node节点为分组ClientRequest</li>
<li>调用NetWorkClient的send方法，做好发送ClientRequest的准备</li>
<li>全部就绪后调用NetWorkClient的poll方法，触发网络IO，把消息真正发送出去</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zgyyq.github.io/blog/2023/04/25/%E7%AE%97%E6%B3%95/%E9%80%92%E5%BD%92/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="最光阴">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="最光阴写字的地方">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/2023/04/25/%E7%AE%97%E6%B3%95/%E9%80%92%E5%BD%92/" class="post-title-link" itemprop="url">post</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-04-25 22:00:49 / 修改时间：22:02:02" itemprop="dateCreated datePublished" datetime="2023-04-25T22:00:49+08:00">2023-04-25</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zgyyq.github.io/blog/2023/04/21/kafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6/%E3%80%8CKafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6%E3%80%8D%E4%B9%8BRecordAccumulator/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="最光阴">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="最光阴写字的地方">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/2023/04/21/kafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6/%E3%80%8CKafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6%E3%80%8D%E4%B9%8BRecordAccumulator/" class="post-title-link" itemprop="url">「Kafka源码美学」之RecordAccumulator - 数据累加器</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-04-21 21:59:15" itemprop="dateCreated datePublished" datetime="2023-04-21T21:59:15+08:00">2023-04-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-04-30 01:03:07" itemprop="dateModified" datetime="2023-04-30T01:03:07+08:00">2023-04-30</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/Kafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6/" itemprop="url" rel="index"><span itemprop="name">Kafka源码美学</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Hello 大家好，我是最光阴。在上一篇文章中介绍了Kafka生产者的核心流程，可见Kafka将各个功能模块进行拆分，每个模块都具有独立的功能和职责。接下来，让我们一起探讨每个模板的细节，体验Kafka源码设计的美学。</p>
<p>首先让我们来看下RecordAccumulator - 数据累加器。</p>
<h2 id="RecordAccumulator的存储结构："><a href="#RecordAccumulator的存储结构：" class="headerlink" title="RecordAccumulator的存储结构："></a>RecordAccumulator的存储结构：</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> ConcurrentMap&lt;String <span class="comment">/*topic*/</span>, TopicInfo&gt; topicInfoMap = <span class="keyword">new</span> <span class="title class_">CopyOnWriteMap</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">TopicInfo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> ConcurrentMap&lt;Integer <span class="comment">/*partition*/</span>, Deque&lt;ProducerBatch&gt;&gt; batches = <span class="keyword">new</span> <span class="title class_">CopyOnWriteMap</span>&lt;&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h2><p><img src="/blog/img/kafka%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97/RecordAccumulator.png" alt="img"></p>
<p>RecordAccumulator实现了缓存消息，以topic、partition为单元，把消息以ProducerBatch为单位累积。多个ProducerBatch保存在Deque队列中。当Deque中最新的batch已不能容纳消息时，就会创建新的batch来继续缓存，并将其加入Deque。</p>
<h2 id="RecordAccumulator代码分析"><a href="#RecordAccumulator代码分析" class="headerlink" title="RecordAccumulator代码分析"></a>RecordAccumulator代码分析</h2><h3 id="Append"><a href="#Append" class="headerlink" title="Append"></a>Append</h3><p>append()方法是RecordAccumulator暴露的累积消息入口，KafkaProducer通过此接口累积消息。我们也先从此方法开始层层递进，分析累积消息的逻辑。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> RecordAppendResult <span class="title function_">append</span><span class="params">(String topic,</span></span><br><span class="line"><span class="params">                                     <span class="type">int</span> partition,</span></span><br><span class="line"><span class="params">                                     <span class="type">long</span> timestamp,</span></span><br><span class="line"><span class="params">                                     <span class="type">byte</span>[] key,</span></span><br><span class="line"><span class="params">                                     <span class="type">byte</span>[] value,</span></span><br><span class="line"><span class="params">                                     Header[] headers,</span></span><br><span class="line"><span class="params">                                     AppendCallbacks callbacks,</span></span><br><span class="line"><span class="params">                                     <span class="type">long</span> maxTimeToBlock,</span></span><br><span class="line"><span class="params">                                     <span class="type">boolean</span> abortOnNewBatch,</span></span><br><span class="line"><span class="params">                                     <span class="type">long</span> nowMs,</span></span><br><span class="line"><span class="params">                                     Cluster cluster)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 获取或初始化topicInfo</span></span><br><span class="line">        <span class="type">TopicInfo</span> <span class="variable">topicInfo</span> <span class="operator">=</span> topicInfoMap.computeIfAbsent(topic, k -&gt; <span class="keyword">new</span> <span class="title class_">TopicInfo</span>(logContext, k, batchSize));</span><br><span class="line"></span><br><span class="line">        <span class="type">ByteBuffer</span> <span class="variable">buffer</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">                <span class="comment">// 获取或初始化发送队列</span></span><br><span class="line">                Deque&lt;ProducerBatch&gt; dq = topicInfo.batches.computeIfAbsent(effectivePartition, k -&gt; <span class="keyword">new</span> <span class="title class_">ArrayDeque</span>&lt;&gt;());</span><br><span class="line">                <span class="comment">// 队列是线程不安全的，所以往队列中添加元素时需要加锁</span></span><br><span class="line">                <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">                    <span class="comment">// 尝试添加将数据添加到队列尾部</span></span><br><span class="line">                    <span class="type">RecordAppendResult</span> <span class="variable">appendResult</span> <span class="operator">=</span> tryAppend(timestamp, key, value, headers, callbacks, dq, nowMs);</span><br><span class="line">                    <span class="keyword">if</span> (appendResult != <span class="literal">null</span>) &#123;</span><br><span class="line">                        <span class="keyword">return</span> appendResult;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 到这里则表明需要新申请producerBatch，用来存储新数据</span></span><br><span class="line">                <span class="keyword">if</span> (buffer == <span class="literal">null</span>) &#123;</span><br><span class="line">                    <span class="comment">// 从BufferPool申请ByteBuffer。如果BufferPool空间不足就轮询等待。</span></span><br><span class="line">                    buffer = free.allocate(size, maxTimeToBlock);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">                    <span class="comment">// 添加一个新的batch到队列</span></span><br><span class="line">                    <span class="type">RecordAppendResult</span> <span class="variable">appendResult</span> <span class="operator">=</span> appendNewBatch(topic, effectivePartition, dq, timestamp, key, value, headers, callbacks, buffer, nowMs);</span><br><span class="line">                    <span class="keyword">return</span> appendResult;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            free.deallocate(buffer);</span><br><span class="line">            appendsInProgress.decrementAndGet();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>append()方法中主要是将数据追加到ProducerBatch中。代码中有两次追加操作：</p>
<ol>
<li>往已有的ProducerBatch中追加数据</li>
<li>如果ProducerBatch已满或者不存在，则创建一个新的ProducerBatch，存储数据</li>
</ol>
<p>不难发现，数据追加的操作是线程不安全的，而kafka使用了一种<strong>细粒度</strong>的锁。只有在追加相同partition数据时，才会加锁，提高效率。</p>
<h3 id="TryAppend"><a href="#TryAppend" class="headerlink" title="TryAppend"></a>TryAppend</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> RecordAppendResult <span class="title function_">tryAppend</span><span class="params">(<span class="type">long</span> timestamp, <span class="type">byte</span>[] key, <span class="type">byte</span>[] value, Header[] headers,</span></span><br><span class="line"><span class="params">                                        Callback callback, Deque&lt;ProducerBatch&gt; deque, <span class="type">long</span> nowMs)</span> &#123;</span><br><span class="line">       <span class="comment">// 获取最新的一个ProducerBatch</span></span><br><span class="line">       <span class="type">ProducerBatch</span> <span class="variable">last</span> <span class="operator">=</span> deque.peekLast();</span><br><span class="line">       <span class="keyword">if</span> (last != <span class="literal">null</span>) &#123;</span><br><span class="line">           <span class="comment">// 如果last!=null ,则证明存在已有的ProducerBatch，则需要判断是否在额外的空间支持存储新的数据</span></span><br><span class="line">           <span class="type">int</span> <span class="variable">initialBytes</span> <span class="operator">=</span> last.estimatedSizeInBytes();</span><br><span class="line">           <span class="type">FutureRecordMetadata</span> <span class="variable">future</span> <span class="operator">=</span> last.tryAppend(timestamp, key, value, headers, callback, nowMs);</span><br><span class="line">           <span class="comment">// 没有额外的空间，返回null，在上层创建新的ProducerBatch</span></span><br><span class="line">           <span class="keyword">if</span> (future == <span class="literal">null</span>) &#123;</span><br><span class="line">               last.closeForRecordAppends();</span><br><span class="line">           &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">               <span class="type">int</span> <span class="variable">appendedBytes</span> <span class="operator">=</span> last.estimatedSizeInBytes() - initialBytes;</span><br><span class="line">               <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">RecordAppendResult</span>(future, deque.size() &gt; <span class="number">1</span> || last.isFull(), <span class="literal">false</span>, <span class="literal">false</span>, appendedBytes);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p>tryAppend()方法是希望将数据追加到已存在的ProducerBatch中，如果有额外的空间，则直接写入。没有则需要上层创建新的ProducerBatch存储。</p>
<h3 id="AppendNewBatch"><a href="#AppendNewBatch" class="headerlink" title="AppendNewBatch"></a>AppendNewBatch</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> RecordAppendResult <span class="title function_">appendNewBatch</span><span class="params">(String topic,</span></span><br><span class="line"><span class="params">                                              <span class="type">int</span> partition,</span></span><br><span class="line"><span class="params">                                              Deque&lt;ProducerBatch&gt; dq,</span></span><br><span class="line"><span class="params">                                              <span class="type">long</span> timestamp,</span></span><br><span class="line"><span class="params">                                              <span class="type">byte</span>[] key,</span></span><br><span class="line"><span class="params">                                              <span class="type">byte</span>[] value,</span></span><br><span class="line"><span class="params">                                              Header[] headers,</span></span><br><span class="line"><span class="params">                                              AppendCallbacks callbacks,</span></span><br><span class="line"><span class="params">                                              ByteBuffer buffer,</span></span><br><span class="line"><span class="params">                                              <span class="type">long</span> nowMs)</span> &#123;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 因为两次加锁操作并不能保证串行，第一次tryAppend不成功后，需要创建新的ProducerBatch，但有可能其他的线程抢先创建了这个ProducerBatch，所以这里需要再次tryAppend操作</span></span><br><span class="line">        <span class="type">RecordAppendResult</span> <span class="variable">appendResult</span> <span class="operator">=</span> tryAppend(timestamp, key, value, headers, callbacks, dq, nowMs);</span><br><span class="line">        <span class="keyword">if</span> (appendResult != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> appendResult;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 创建MemoryRecordsBuilder对象，真正存储消息的地方</span></span><br><span class="line">        <span class="type">MemoryRecordsBuilder</span> <span class="variable">recordsBuilder</span> <span class="operator">=</span> recordsBuilder(buffer, apiVersions.maxUsableProduceMagic());</span><br><span class="line">        <span class="comment">// 创建一个新的ProducerBatch</span></span><br><span class="line">        <span class="type">ProducerBatch</span> <span class="variable">batch</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ProducerBatch</span>(<span class="keyword">new</span> <span class="title class_">TopicPartition</span>(topic, partition), recordsBuilder, nowMs);</span><br><span class="line">        <span class="comment">// 往ProducerBatch中追加消息</span></span><br><span class="line">        <span class="type">FutureRecordMetadata</span> <span class="variable">future</span> <span class="operator">=</span> Objects.requireNonNull(batch.tryAppend(timestamp, key, value, headers,</span><br><span class="line">                callbacks, nowMs));</span><br><span class="line"></span><br><span class="line">        dq.addLast(batch);</span><br><span class="line">        incomplete.add(batch);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">RecordAppendResult</span>(future, dq.size() &gt; <span class="number">1</span> || batch.isFull(), <span class="literal">true</span>, <span class="literal">false</span>, batch.estimatedSizeInBytes());</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>appendNewBatch中需要再次tryAppend，有点像我们在写懒汉式单例时的实现。</p>
<p>最后我们总结一下：</p>
<p>1、RecordAccumulator使用ProducerBatch缓存消息。路由规则是 topic -&gt; partition -&gt; producerBatch。也就是每个主题分区都拥有一个batch队列，只有追加相同队列时才需要加锁。</p>
<p>2、当Deque的队尾producerBatch容量不足时，会创建新的ProducerBatch放入队尾来存放新消息。</p>
<p>3、ProducerBatch对消息追加的操作都是通过MemoryRecordsBuilder进行的。消息最终被追加到MemoryRecordsBuilder中的DataOutputStream appendStream中</p>
<p>本文分析了Kafka消息的追加代码，可知消息是暂存在RecordAccumulator中的，接下来我们来看看消息是怎么被发送出去的。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zgyyq.github.io/blog/2023/04/16/kafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6/%E3%80%8CKafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6%E3%80%8D%E4%B9%8BProducer%E6%A0%B8%E5%BF%83%E6%B5%81%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="最光阴">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="最光阴写字的地方">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/2023/04/16/kafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6/%E3%80%8CKafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6%E3%80%8D%E4%B9%8BProducer%E6%A0%B8%E5%BF%83%E6%B5%81%E7%A8%8B/" class="post-title-link" itemprop="url">「Kafka源码美学」之Producer核心流程</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-04-16 14:57:39" itemprop="dateCreated datePublished" datetime="2023-04-16T14:57:39+08:00">2023-04-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-04-30 01:11:43" itemprop="dateModified" datetime="2023-04-30T01:11:43+08:00">2023-04-30</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/Kafka%E6%BA%90%E7%A0%81%E7%BE%8E%E5%AD%A6/" itemprop="url" rel="index"><span itemprop="name">Kafka源码美学</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Hello，大家好，我是最光阴。最近一直在看Kafka的源码，获益良多，所以准备写一个系列来介绍Kafka源码设计的美学。</p>
<p>现在让我们开始『kafka源码美学』系列专题的第一篇：生产者流程。在本篇文章中，我们将探索 Kafka 生产者的内部机制，揭示它如何在消息传递方面表现出卓越的性能和可靠性。</p>
<p>首先让我们来看下生产者的架构图</p>
<h2 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h2><p><img src="/blog/img/kafka%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97/%E7%94%9F%E4%BA%A7%E8%80%85%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="img"></p>
<p>在生产一条消息时，会先后经过<strong>拦截器</strong>、<strong>序列化器</strong>对消息进行处理，再经过<strong>分区器</strong>确定消息发送在具体topic下的哪个分区，然后发送到对应的消息累加器中。</p>
<p><strong>sender线程</strong>会读取<strong>消息累加器</strong>中的数据，再包装成Request通过Selector发送到Kafka集群。</p>
<p><strong>可见Kafka的发送流程其实是个异步的流程</strong></p>
<p>接下来看看Kafka代码中是如何实现的。</p>
<h2 id="客户端代码"><a href="#客户端代码" class="headerlink" title="客户端代码"></a>客户端代码</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Main</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;127.0.0.1:9092&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;acks&quot;</span>, <span class="string">&quot;all&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;retries&quot;</span>, <span class="number">0</span>);</span><br><span class="line">        props.put(<span class="string">&quot;batch.size&quot;</span>, <span class="number">16384</span>);</span><br><span class="line">        props.put(<span class="string">&quot;key.serializer&quot;</span>, StringSerializer.class.getName());</span><br><span class="line">        props.put(<span class="string">&quot;value.serializer&quot;</span>, StringSerializer.class.getName());</span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">        String[] values = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;111&quot;</span>, <span class="string">&quot;222&quot;</span>, <span class="string">&quot;33&quot;</span>&#125;;</span><br><span class="line">        ProducerRecord&lt;String, String&gt; producerRecord = <span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;String, String&gt;(<span class="string">&quot;quickstart-events&quot;</span>, <span class="string">&quot;key&quot;</span>, values.toString());</span><br><span class="line">        producer.send(producerRecord);</span><br><span class="line">        producer.close();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Producer初始化"><a href="#Producer初始化" class="headerlink" title="Producer初始化"></a>Producer初始化</h2><p>首先分析KafkaProducer的初始化：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(props);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">KafkaProducer(ProducerConfig config,</span><br><span class="line">                  Serializer&lt;K&gt; keySerializer,</span><br><span class="line">                  Serializer&lt;V&gt; valueSerializer,</span><br><span class="line">                  ProducerMetadata metadata,</span><br><span class="line">                  KafkaClient kafkaClient,</span><br><span class="line">                  ProducerInterceptors&lt;K, V&gt; interceptors,</span><br><span class="line">                  Time time) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// ....... 省略一些代码</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">// 获取配置的分区器（如果没有配置，则使用默认的org.apache.kafka.clients.producer.DefaultPartitioner），后面用来决定，发送的每条消息是路由到Topic的哪个分区里去的</span></span><br><span class="line">            <span class="built_in">this</span>.partitioner = config.getConfiguredInstance(</span><br><span class="line">                    ProducerConfig.PARTITIONER_CLASS_CONFIG,</span><br><span class="line">                    Partitioner.class,</span><br><span class="line">                    Collections.singletonMap(ProducerConfig.CLIENT_ID_CONFIG, clientId));</span><br><span class="line"></span><br><span class="line">           </span><br><span class="line">            <span class="comment">// 初始化核心组件：RecordAccumulator，它是一个发送消息数据的记录累加器，用于批量发送消息数据</span></span><br><span class="line">            <span class="built_in">this</span>.accumulator = <span class="keyword">new</span> <span class="title class_">RecordAccumulator</span>(logContext,</span><br><span class="line">                    batchSize,</span><br><span class="line">                    <span class="built_in">this</span>.compressionType,</span><br><span class="line">                    lingerMs(config),</span><br><span class="line">                    retryBackoffMs,</span><br><span class="line">                    deliveryTimeoutMs,</span><br><span class="line">                    partitionerConfig,</span><br><span class="line">                    metrics,</span><br><span class="line">                    PRODUCER_METRIC_GROUP_NAME,</span><br><span class="line">                    time,</span><br><span class="line">                    apiVersions,</span><br><span class="line">                    transactionManager,</span><br><span class="line">                    <span class="keyword">new</span> <span class="title class_">BufferPool</span>(<span class="built_in">this</span>.totalMemorySize, batchSize, metrics, time, PRODUCER_METRIC_GROUP_NAME));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment">// 初始化核心组件：metadata，它记录了生产者的源信息，包括集群信息、topic信息等</span></span><br><span class="line">            <span class="built_in">this</span>.metadata = <span class="keyword">new</span> <span class="title class_">ProducerMetadata</span>(retryBackoffMs,</span><br><span class="line">                        config.getLong(ProducerConfig.METADATA_MAX_AGE_CONFIG),</span><br><span class="line">                        config.getLong(ProducerConfig.METADATA_MAX_IDLE_CONFIG),</span><br><span class="line">                        logContext,</span><br><span class="line">                        clusterResourceListeners,</span><br><span class="line">                        Time.SYSTEM);</span><br><span class="line">            <span class="built_in">this</span>.metadata.bootstrap(addresses);</span><br><span class="line">        </span><br><span class="line">            <span class="comment">// 初始化核心组件：sender, 它封装了具体的发送流程</span></span><br><span class="line">            <span class="built_in">this</span>.sender = newSender(logContext, kafkaClient, <span class="built_in">this</span>.metadata);</span><br><span class="line">            <span class="type">String</span> <span class="variable">ioThreadName</span> <span class="operator">=</span> NETWORK_THREAD_PREFIX + <span class="string">&quot; | &quot;</span> + clientId;</span><br><span class="line">            <span class="comment">// 创建io线程，执行sender方法</span></span><br><span class="line">            <span class="built_in">this</span>.ioThread = <span class="keyword">new</span> <span class="title class_">KafkaThread</span>(ioThreadName, <span class="built_in">this</span>.sender, <span class="literal">true</span>);</span><br><span class="line">            <span class="comment">// 启动线程</span></span><br><span class="line">            <span class="built_in">this</span>.ioThread.start();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// ....... 省略一些代码</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">           </span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>可见KafkaProducer初始化时构建了一系列的核心组件：</p>
<ol>
<li>Partitioner（分区器），决定消息路由到Topic的哪个分区里</li>
<li>Metadata（元数据），定期向集群拉取元数据信息更新。配置 metadata.max.age.ms 时间间隔，默认是5分钟，默认每隔5分钟一定会强制刷新一下</li>
<li>RecordAccumulator（数据累加器），负责消息的缓冲机制，发送到每个分区的消息会被封装成batch，一般batch size是16kb，默认情况下要凑够一个batch才会发送，但是可以设置 linger.ms，如果在指定时间范围内，都没凑出来一个batch就把这条消息发送出去，比如说5ms，如果5ms还没凑出来一个batch，那么就必须立即把这个消息发送出去</li>
<li>Sender（发送器），负责从缓冲区里获取消息发送到broker上去</li>
</ol>
<p><strong>其源码设计中充分体现了组合优于继承的思想。</strong></p>
<p>Kafka将各个功能模块进行拆分，每个模块都具有独立的功能和职责，这样可以使得代码更加模块化和可维护。</p>
<p>后续会为每个模块单独写一篇文章详细讲解。</p>
<h2 id="producer-send"><a href="#producer-send" class="headerlink" title="producer.send()"></a>producer.send()</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">private</span> Future&lt;RecordMetadata&gt; <span class="title function_">doSend</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> &#123;</span><br><span class="line">    <span class="comment">// 序列化key</span></span><br><span class="line">    serializedKey = keySerializer.serialize(record.topic(), record.headers(), record.key());</span><br><span class="line">    <span class="comment">// 序列号value</span></span><br><span class="line">    serializedValue = valueSerializer.serialize(record.topic(), record.headers(), record.value());</span><br><span class="line">    <span class="comment">// 根据分区器算法计算应该往哪个分区中发送消息</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">partition</span> <span class="operator">=</span> partition(record, serializedKey, serializedValue, cluster);</span><br><span class="line">    <span class="comment">// 将消息追加到 RecordAccumulator中，由accumulator封装成batch发送</span></span><br><span class="line">    RecordAccumulator.<span class="type">RecordAppendResult</span> <span class="variable">result</span> <span class="operator">=</span> accumulator.append(record.topic(), partition, timestamp, serializedKey,</span><br><span class="line">                    serializedValue, headers, appendCallbacks, remainingWaitMs, abortOnNewBatch, nowMs, cluster);</span><br><span class="line">    <span class="comment">// 如果该批次满了，或者是新创建的批次，则唤醒sender线程，进行消息发送</span></span><br><span class="line">    <span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;</span><br><span class="line">                log.trace(<span class="string">&quot;Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch&quot;</span>, record.topic(), appendCallbacks.getPartition());</span><br><span class="line">                <span class="built_in">this</span>.sender.wakeup();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>doSend() 主要是三个步骤：</p>
<ol>
<li>序列化 record 的 key 和 value</li>
<li>获取该 record 要发送到的 partition（可以指定，也可以根据算法计算）</li>
<li>向 accumulator 中追加 record 数据，数据会先进行缓存（默认32M）</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">最光阴</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/blog/archives/">
        
          <span class="site-state-item-count">6</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/blog/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">最光阴</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/blog/lib/anime.min.js"></script>
  <script src="/blog/lib/velocity/velocity.min.js"></script>
  <script src="/blog/lib/velocity/velocity.ui.min.js"></script>

<script src="/blog/js/utils.js"></script>

<script src="/blog/js/motion.js"></script>


<script src="/blog/js/schemes/pisces.js"></script>


<script src="/blog/js/next-boot.js"></script>




  















  

  

</body>
</html>
